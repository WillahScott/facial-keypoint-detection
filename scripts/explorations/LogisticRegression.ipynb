{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the path\n",
    "import sys, os\n",
    "\n",
    "pathArr = os.getcwd().split(\"/\")\n",
    "scriptPath = '/'.join(map(str, pathArr[:len(pathArr)-1]))\n",
    "sys.path.append(scriptPath)\n",
    "\n",
    "# import my tools\n",
    "from tools import save4later, submit, getdata\n",
    "\n",
    "# import the sklearn libraries and numpy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 30\n",
      "Training dataset size:  (2140,)\n",
      "Test dataset size:  (1783,)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "_loaded = getdata.load_data(0, test=True, nonas=True)\n",
    "\n",
    "FEATURES = _loaded['features']\n",
    "print 'Number of features:', len(FEATURES)\n",
    "\n",
    "train_data = _loaded['training']['data']\n",
    "train_labels = _loaded['training']['labels']\n",
    "print 'Training dataset size: ', train_data.shape\n",
    "\n",
    "test_data = _loaded['test']['data']\n",
    "print 'Test dataset size: ', test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a list to hold logistic regressions\n",
    "logistics = []\n",
    "\n",
    "# initalize a potential set of reasonable C values\n",
    "#Lparameters = {'C':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 100.0]}\n",
    "\n",
    "# loop through every facial feature\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "\n",
    "    # initalize the logistic regression model\n",
    "    logistic = LogisticRegression()\n",
    "\n",
    "    # set the C search with the given C options and the logistic model\n",
    "    #C_search = GridSearchCV(logistic,Lparameters)\n",
    "\n",
    "    # fit the Gridsearch model to the data\n",
    "    #C_search.fit(train_data.tolist(),train_labels[:,index])\n",
    "\n",
    "    # find the best C parameter\n",
    "    #best_C = C_search.best_params_\n",
    "\n",
    "    # initalize a model with the best C\n",
    "    #logistic_optimal = LogisticRegression(C = best_C['C'])\n",
    "    #logistic_optimal.fit(train_data.tolist(),train_labels[:,index])\n",
    "    logistic_optimal = logistic.fit(train_data.tolist(),train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the name of the feature and the model\n",
    "    appending = facial_feature, logistic_optimal\n",
    "    \n",
    "    # append the name and the model to our list of facial feature models\n",
    "    logistics.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(logistics, 'Logistic', \n",
    "                      'Logistic regression with non-preprocessed data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "logistics = save4later.load_model(\"Logistic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the models on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (0.3s)\n",
      "Predicting \"left_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"nose_tip_x\"... done! (0.1s)\n",
      "Predicting \"nose_tip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (0.2s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (0.2s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (0.2s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (0.1s)\n",
      "\n",
      "... Created the csv file: ../../data/submissions/logistics_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, logistics, 'logistics', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the accuracies on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          Accuracy\n",
      " - left_eye_center_x           100.000%\n",
      " - left_eye_center_y           100.000%\n",
      " - right_eye_center_x          100.000%\n",
      " - right_eye_center_y          100.000%\n",
      " - left_eye_inner_corner_x     100.000%\n",
      " - left_eye_inner_corner_y     100.000%\n",
      " - left_eye_outer_corner_x     100.000%\n",
      " - left_eye_outer_corner_y     100.000%\n",
      " - right_eye_inner_corner_x    100.000%\n",
      " - right_eye_inner_corner_y    100.000%\n",
      " - right_eye_outer_corner_x    100.000%\n",
      " - right_eye_outer_corner_y    100.000%\n",
      " - left_eyebrow_inner_end_x    100.000%\n",
      " - left_eyebrow_inner_end_y    100.000%\n",
      " - left_eyebrow_outer_end_x    100.000%\n",
      " - left_eyebrow_outer_end_y    100.000%\n",
      " - right_eyebrow_inner_end_x   100.000%\n",
      " - right_eyebrow_inner_end_y   100.000%\n",
      " - right_eyebrow_outer_end_x   100.000%\n",
      " - right_eyebrow_outer_end_y   100.000%\n",
      " - nose_tip_x                  100.000%\n",
      " - nose_tip_y                  100.000%\n",
      " - mouth_left_corner_x         100.000%\n",
      " - mouth_left_corner_y         100.000%\n",
      " - mouth_right_corner_x        100.000%\n",
      " - mouth_right_corner_y        100.000%\n",
      " - mouth_center_top_lip_x      100.000%\n",
      " - mouth_center_top_lip_y      100.000%\n",
      " - mouth_center_bottom_lip_x   100.000%\n",
      " - mouth_center_bottom_lip_y   100.000%\n"
     ]
    }
   ],
   "source": [
    "print \"{:30} Accuracy\".format(\"Model\")\n",
    "\n",
    "# use the models to predict the dev data\n",
    "for index,(feat,model) in enumerate(logistics):\n",
    "    predications = model.predict(train_data.tolist())\n",
    "    accuracy = np.mean(1 - abs(train_labels[:,index] - predications)/96)\n",
    "    print \" - {f:<27} {a:.3%}\".format(f=FEATURES[index],a=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the logistic regression on 'masked' preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "# load the masked training data\n",
    "train_masked = save4later.load_preprod(\"masked_nonas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list to hold logistic regressions\n",
    "Mask_logistics = []\n",
    "\n",
    "# initalize a potential set of reasonable C values\n",
    "#Lparameters = {'C':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 100.0]}\n",
    "\n",
    "# loop through every facial feature\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "\n",
    "    # initalize the logistic regression model\n",
    "    logistic = LogisticRegression()\n",
    "\n",
    "    # set the C search with the given C options and the logistic model\n",
    "    #C_search = GridSearchCV(logistic,Lparameters)\n",
    "\n",
    "    # fit the Gridsearch model to the data\n",
    "    #C_search.fit(train_masked,train_labels[:,index])\n",
    "\n",
    "    # find the best C parameter\n",
    "    #best_C = C_search.best_params_\n",
    "\n",
    "    # initalize a model with the best C\n",
    "    #logistic_optimal = LogisticRegression(C = best_C['C'])\n",
    "    #logistic_optimal.fit(train_masked,train_labels[:,index])\n",
    "    logistic_optimal = logistic.fit(train_masked, train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the name of the feature and the model\n",
    "    appending = facial_feature, logistic_optimal\n",
    "    \n",
    "    # append the name and the model to our list of facial feature models\n",
    "    Mask_logistics.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(Mask_logistics, 'Logistic_Mask', \n",
    "                      'Logistic regression with masked data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracies on the masked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"{:30} Accuracy\".format(\"Model\")\n",
    "\n",
    "# use the models to predict the dev data\n",
    "for index,(feat,model) in enumerate(Mask_logistics):\n",
    "    predications = model.predict(train_masked)\n",
    "    accuracy = np.mean(1 - abs(train_labels[:,index] - predications)/96)\n",
    "    print \" - {f:<27} {a:.3%}\".format(f=FEATURES[index],a=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
