{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Feature - Baseline Submission  \n",
    "\n",
    "The following notebook contains the baseline submission by the team composed of Alex, Ankit, Annalaissa, Nina and Guillermo for the [Facial Keypoints Detection](https://www.kaggle.com/c/facial-keypoints-detection) Kaggle competition.  \n",
    "\n",
    "Several Machine Learning teachniques were initially tested but the selected approach was the use of a *default* **K-Nearest Neighbors Regressor**, with accuracies on development data around 90% - 95%.  \n",
    "\n",
    "A KN-Regression model was trained independently for each feature coordinate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data  \n",
    "Preprocessing filters all images with null labels.  \n",
    "No dev set created for baseline submission.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "full_data = pd.read_csv(\"data/training.csv\")\n",
    "\n",
    "# Preprocess images into unsigned 8byte integer arrays\n",
    "get_img = lambda x: np.uint8( map(int, x.split()) )\n",
    "full_data['img_processed'] = map( get_img, full_data['Image'])\n",
    "\n",
    "# fill na\n",
    "data_nonas = full_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get training data\n",
    "train_data = data_nonas.iloc[:,31].values\n",
    "train_labels = np.round(data_nonas.iloc[:,:30].values)\n",
    "\n",
    "# For base submission no (dev data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test_data\n",
    "full_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Preprocess images into unsigned 8byte integer arrays\n",
    "get_img = lambda x: np.uint8( map(int, x.split()) )\n",
    "full_test['img_processed'] = map( get_img, full_test['Image'])\n",
    "\n",
    "# Get training data\n",
    "test_data = full_test[['img_processed']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train KN-Regressor model for each feature coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get list of models\n",
    "kn_regressors = []\n",
    "\n",
    "# Get all models\n",
    "for i, facial_feature in enumerate(data_nonas.columns[:-2]):\n",
    "    \n",
    "    knn = KNeighborsRegressor()\n",
    "    knn.fit(train_data.tolist(), train_labels[:,i])\n",
    "    \n",
    "    kn_regressors.append( (facial_feature, knn) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test data and create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(test, models, label='baseline', verbose=False):\n",
    "    ''' Predict and generate submission file \n",
    "    Inputs: \n",
    "        test - test dataset on which to predict\n",
    "        models - list of tuples: [ (feature, model), ... ]\n",
    "        label - label for identification of the submission file\n",
    "    \n",
    "    Usage: >> create_submission( <test_data>, <list_of_models> [, <label> ] )\n",
    "    '''\n",
    "    \n",
    "    predicted_df = pd.DataFrame()\n",
    "    \n",
    "    # get predictions on test dataset\n",
    "    for (f, mod) in models:  # 'models' is a list of tuples ('facial_feature', model)\n",
    "        \n",
    "        if verbose:\n",
    "            print 'Predicting \"{}\"...'.format(f),\n",
    "        \n",
    "        _start = time.time()  # start timer\n",
    "        predicted_df[f] = mod.predict(test.iloc[:,0].tolist())\n",
    "        _elapsed = time.time() - _start\n",
    "        \n",
    "        if verbose:\n",
    "            print 'done! ({:.1f}s)'.format(_elapsed)\n",
    "    \n",
    "    # create the csv file\n",
    "    generate_csv(predicted_df, label)\n",
    "    \n",
    "    return predicted_df\n",
    "\n",
    "def generate_csv(df, label):\n",
    "    ''' Generate csv file with the submission format\n",
    "    Inputs:\n",
    "        df - dataframe with predictions\n",
    "        label - label to identify the submission file\n",
    "    \n",
    "    Usage: >> generate_csv(<data_frame_with_predictions>, <label>)\n",
    "    '''\n",
    "    \n",
    "    # Get full flat frame\n",
    "    out = pd.DataFrame()\n",
    "    out['Location'] = df.values.flatten()\n",
    "    out['RowId'] = np.arange(1,len(out)+1)\n",
    "    out = out[['RowId','Location']]\n",
    "    \n",
    "    # Unpivot data, filter with SampleSubmission\n",
    "    unpivot = pd.melt(kn_predictions.reset_index(), id_vars='index')\n",
    "    unpivot.columns = ['ImageId', 'FeatureName', 'Location']\n",
    "    scored_sub = pd.merge(id_t[['RowId', 'ImageId', 'FeatureName']], unpivot,\n",
    "                          on=['ImageId', 'FeatureName'], how='left')\n",
    "        \n",
    "    # Export only RowId and Location columns\n",
    "    final = scored_sub[['RowId','Location']]\n",
    "    with open('data/{}_submission.csv'.format(label), 'wb') as f:\n",
    "        final.to_csv(f, index=False)\n",
    "    \n",
    "    print '... Created the csv file: data/{}_submission.csv'.format(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (55.6s)\n",
      "Predicting \"left_eye_center_y\"... done! (54.8s)\n",
      "Predicting \"right_eye_center_x\"... done! (53.9s)\n",
      "Predicting \"right_eye_center_y\"... done! (54.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (54.3s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (54.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (55.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (57.6s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (54.5s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (55.0s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (54.2s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (54.0s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (54.0s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (54.2s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (55.2s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (54.2s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (55.3s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (58.9s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (55.7s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (55.4s)\n",
      "Predicting \"nose_tip_x\"... done! (55.9s)\n",
      "Predicting \"nose_tip_y\"... done! (56.0s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (54.5s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (55.4s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (55.1s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (56.2s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (55.0s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (55.6s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (54.6s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (56.3s)\n",
      "... Created the csv file: data/full_knregressor_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Create submission!! :)\n",
    "kn_predictions = create_submission(test_data, kn_regressors, 'full_knregressor', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate csv again, because I changed the function definition while debugging. (Overwriting incorrect version of `full_knregressor_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Created the csv file: data/full_knregressor_submission.csv\n"
     ]
    }
   ],
   "source": [
    "generate_csv(kn_predictions, 'full_knregressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check submission csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df = pd.read_csv('data/full_knregressor_submission.csv')\n",
    "\n",
    "print _df.shape\n",
    "_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
