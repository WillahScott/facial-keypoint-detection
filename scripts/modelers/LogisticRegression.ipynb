{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the path\n",
    "import sys, os\n",
    "\n",
    "pathArr = os.getcwd().split(\"/\")\n",
    "scriptPath = '/'.join(map(str, pathArr[:len(pathArr)-1]))\n",
    "sys.path.append(scriptPath)\n",
    "\n",
    "# import my tools\n",
    "from tools import save4later, submit, getdata\n",
    "\n",
    "# import the sklearn libraries and numpy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 30\n",
      "Training dataset size:  (2140,)\n",
      "Test dataset size:  (1783,)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "_loaded = getdata.load_data(0, test=True, nonas=True)\n",
    "\n",
    "FEATURES = _loaded['features']\n",
    "print 'Number of features:', len(FEATURES)\n",
    "\n",
    "train_data = _loaded['training']['data']\n",
    "train_labels = _loaded['training']['labels']\n",
    "print 'Training dataset size: ', train_data.shape\n",
    "\n",
    "test_data = _loaded['test']['data']\n",
    "print 'Test dataset size: ', test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a list to hold logistic regressions\n",
    "logistics = []\n",
    "\n",
    "# initalize a potential set of reasonable C values\n",
    "#Lparameters = {'C':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 100.0]}\n",
    "\n",
    "# loop through every facial feature\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "\n",
    "    # initalize the logistic regression model\n",
    "    logistic = LogisticRegression()\n",
    "\n",
    "    # set the C search with the given C options and the logistic model\n",
    "    #C_search = GridSearchCV(logistic,Lparameters)\n",
    "\n",
    "    # fit the Gridsearch model to the data\n",
    "    #C_search.fit(train_data.tolist(),train_labels[:,index])\n",
    "\n",
    "    # find the best C parameter\n",
    "    #best_C = C_search.best_params_\n",
    "\n",
    "    # initalize a model with the best C\n",
    "    #logistic_optimal = LogisticRegression(C = best_C['C'])\n",
    "    #logistic_optimal.fit(train_data.tolist(),train_labels[:,index])\n",
    "    logistic_optimal = logistic.fit(train_data.tolist(),train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the name of the feature and the model\n",
    "    appending = facial_feature, logistic_optimal\n",
    "    \n",
    "    # append the name and the model to our list of facial feature models\n",
    "    logistics.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(logistics, 'Logistic', \n",
    "                      'Logistic regression with non-preprocessed data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "logistics = save4later.load_model(\"Logistic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the models on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (0.3s)\n",
      "Predicting \"left_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"nose_tip_x\"... done! (0.1s)\n",
      "Predicting \"nose_tip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (0.2s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (0.2s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (0.2s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (0.1s)\n",
      "\n",
      "... Created the csv file: ../../data/submissions/logistics_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, logistics, 'logistics', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the accuracies on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          Accuracy\n",
      " - left_eye_center_x           100.000%\n",
      " - left_eye_center_y           100.000%\n",
      " - right_eye_center_x          100.000%\n",
      " - right_eye_center_y          100.000%\n",
      " - left_eye_inner_corner_x     100.000%\n",
      " - left_eye_inner_corner_y     100.000%\n",
      " - left_eye_outer_corner_x     100.000%\n",
      " - left_eye_outer_corner_y     100.000%\n",
      " - right_eye_inner_corner_x    100.000%\n",
      " - right_eye_inner_corner_y    100.000%\n",
      " - right_eye_outer_corner_x    100.000%\n",
      " - right_eye_outer_corner_y    100.000%\n",
      " - left_eyebrow_inner_end_x    100.000%\n",
      " - left_eyebrow_inner_end_y    100.000%\n",
      " - left_eyebrow_outer_end_x    100.000%\n",
      " - left_eyebrow_outer_end_y    100.000%\n",
      " - right_eyebrow_inner_end_x   100.000%\n",
      " - right_eyebrow_inner_end_y   100.000%\n",
      " - right_eyebrow_outer_end_x   100.000%\n",
      " - right_eyebrow_outer_end_y   100.000%\n",
      " - nose_tip_x                  100.000%\n",
      " - nose_tip_y                  100.000%\n",
      " - mouth_left_corner_x         100.000%\n",
      " - mouth_left_corner_y         100.000%\n",
      " - mouth_right_corner_x        100.000%\n",
      " - mouth_right_corner_y        100.000%\n",
      " - mouth_center_top_lip_x      100.000%\n",
      " - mouth_center_top_lip_y      100.000%\n",
      " - mouth_center_bottom_lip_x   100.000%\n",
      " - mouth_center_bottom_lip_y   100.000%\n"
     ]
    }
   ],
   "source": [
    "print \"{:30} Accuracy\".format(\"Model\")\n",
    "\n",
    "# use the models to predict the dev data\n",
    "for index,(feat,model) in enumerate(logistics):\n",
    "    predications = model.predict(train_data.tolist())\n",
    "    accuracy = np.mean(1 - abs(train_labels[:,index] - predications)/96)\n",
    "    print \" - {f:<27} {a:.3%}\".format(f=FEATURES[index],a=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the logistic regression on 'masked' preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "# load the masked training data\n",
    "train_masked = save4later.load_preprod(\"masked_nonas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list to hold logistic regressions\n",
    "Mask_logistics = []\n",
    "\n",
    "# initalize a potential set of reasonable C values\n",
    "#Lparameters = {'C':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 100.0]}\n",
    "\n",
    "# loop through every facial feature\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "\n",
    "    # initalize the logistic regression model\n",
    "    logistic = LogisticRegression()\n",
    "\n",
    "    # set the C search with the given C options and the logistic model\n",
    "    #C_search = GridSearchCV(logistic,Lparameters)\n",
    "\n",
    "    # fit the Gridsearch model to the data\n",
    "    #C_search.fit(train_masked,train_labels[:,index])\n",
    "\n",
    "    # find the best C parameter\n",
    "    #best_C = C_search.best_params_\n",
    "\n",
    "    # initalize a model with the best C\n",
    "    #logistic_optimal = LogisticRegression(C = best_C['C'])\n",
    "    #logistic_optimal.fit(train_masked,train_labels[:,index])\n",
    "    logistic_optimal = logistic.fit(train_masked, train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the name of the feature and the model\n",
    "    appending = facial_feature, logistic_optimal\n",
    "    \n",
    "    # append the name and the model to our list of facial feature models\n",
    "    Mask_logistics.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(Mask_logistics, 'Logistic_Mask', \n",
    "                      'Logistic regression with masked data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mask_logistics = save4later.load_model(\"Logistic_Mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (0.3s)\n",
      "Predicting \"left_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"nose_tip_x\"... done! (0.1s)\n",
      "Predicting \"nose_tip_y\"... done! (0.2s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (0.2s)\n",
      "\n",
      "... Created the csv file: ../../data/submissions/Mask_logistics_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, Mask_logistics, 'Mask_logistics', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracies on the masked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          Accuracy\n",
      " - left_eye_center_x           100.000%\n",
      " - left_eye_center_y           100.000%\n",
      " - right_eye_center_x          100.000%\n",
      " - right_eye_center_y          100.000%\n",
      " - left_eye_inner_corner_x     100.000%\n",
      " - left_eye_inner_corner_y     100.000%\n",
      " - left_eye_outer_corner_x     100.000%\n",
      " - left_eye_outer_corner_y     100.000%\n",
      " - right_eye_inner_corner_x    100.000%\n",
      " - right_eye_inner_corner_y    100.000%\n",
      " - right_eye_outer_corner_x    100.000%\n",
      " - right_eye_outer_corner_y    100.000%\n",
      " - left_eyebrow_inner_end_x    100.000%\n",
      " - left_eyebrow_inner_end_y    100.000%\n",
      " - left_eyebrow_outer_end_x    100.000%\n",
      " - left_eyebrow_outer_end_y    100.000%\n",
      " - right_eyebrow_inner_end_x   100.000%\n",
      " - right_eyebrow_inner_end_y   100.000%\n",
      " - right_eyebrow_outer_end_x   100.000%\n",
      " - right_eyebrow_outer_end_y   100.000%\n",
      " - nose_tip_x                  100.000%\n",
      " - nose_tip_y                  100.000%\n",
      " - mouth_left_corner_x         100.000%\n",
      " - mouth_left_corner_y         100.000%\n",
      " - mouth_right_corner_x        100.000%\n",
      " - mouth_right_corner_y        100.000%\n",
      " - mouth_center_top_lip_x      100.000%\n",
      " - mouth_center_top_lip_y      100.000%\n",
      " - mouth_center_bottom_lip_x   100.000%\n",
      " - mouth_center_bottom_lip_y   100.000%\n"
     ]
    }
   ],
   "source": [
    "print \"{:30} Accuracy\".format(\"Model\")\n",
    "\n",
    "# use the models to predict the dev data\n",
    "for index,(feat,model) in enumerate(Mask_logistics):\n",
    "    predications = model.predict(train_masked)\n",
    "    accuracy = np.mean(1 - abs(train_labels[:,index] - predications)/96)\n",
    "    print \" - {f:<27} {a:.3%}\".format(f=FEATURES[index],a=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the logistic regression model on dimensions reduced data\n",
    "We reduce the dimensions of our data to remove some of the excess noise using principal component analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "# load the PCA training data\n",
    "train_PCA = save4later.load_preprod(\"pca_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a list to hold logistic regressions\n",
    "PCA_logistics = []\n",
    "\n",
    "# initalize a potential set of reasonable C values\n",
    "#Lparameters = {'C':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 100.0]}\n",
    "\n",
    "# loop through every facial feature\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "\n",
    "    # initalize the logistic regression model\n",
    "    logistic = LogisticRegression()\n",
    "\n",
    "    # set the C search with the given C options and the logistic model\n",
    "    #C_search = GridSearchCV(logistic,Lparameters)\n",
    "\n",
    "    # fit the Gridsearch model to the data\n",
    "    #C_search.fit(train_PCA,train_labels[:,index])\n",
    "\n",
    "    # find the best C parameter\n",
    "    #best_C = C_search.best_params_\n",
    "\n",
    "    # initalize a model with the best C\n",
    "    #logistic_optimal = LogisticRegression(C = best_C['C'])\n",
    "    #logistic_optimal.fit(train_masked,train_labels[:,index])\n",
    "    logistic_optimal = logistic.fit(train_PCA, train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the name of the feature and the model\n",
    "    appending = facial_feature, logistic_optimal\n",
    "    \n",
    "    # append the name and the model to our list of facial feature models\n",
    "    PCA_logistics.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(PCA_logistics, 'Logistic_PCA', \n",
    "                      'Logistic regression with PCA data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the models for later\n",
    "save4later.save_model(PCA_logistics, 'Logistic_PCA', \n",
    "                      'Logistic regression with PCA data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    STORED MODELS\n",
      "    =============\n",
      " Total: 14\n",
      "\n",
      "  + Multi_NB_sobel.pk : Multinomial naive bayes with sobel data with no NAs\n",
      "  + MultinomialNB_HOG.pk : Multinomial naive bayes with blurred HOG data with no NAs\n",
      "  + Multi_NB_mask.pk : Multinomial naive bayes with masked data with no NAs\n",
      "  + Logistic_PCA.pk : Logistic regression with PCA data with no NAs\n",
      "  + Logistic.pk : Logistic regression with non-preprocessed data with no NAs\n",
      "  + Logistic_Mask.pk : Logistic regression with masked data with no NAs\n",
      "  + Multi_NB.pk : Multinomial naive bayes without preprocessed data with no NAs\n",
      "  + MultinomialNB_sobel.pk : Multinomial naive bayes with masked data with no NAs\n",
      "  + MultinomialNB.pk : Multinomial naive bayes with non-preprocessed data with no NAs\n",
      "  + MultinomialNB_gauss.pk : Multinomial naive bayes with Gaussian blurred data with no NAs\n",
      "  + Multi_NB_LapG.pk : Multinomial naive bayes with Laplace and Gaussian transformed data with no NAs\n",
      "  + Multi_NB_HOG.pk : Multinomial naive bayes with blurred HOG data with no NAs\n",
      "  + MultinomialNB_Mask.pk : Multinomial naive bayes with masked data with no NAs\n",
      "  + MultinomialNB_LapG.pk : Multinomial naive bayes with Laplace and Gaussian transformed data with no NAs\n"
     ]
    }
   ],
   "source": [
    "save4later.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_logistics = save4later.load_model(\"Logistic_PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.create_generate(test_data, PCA_logistics, 'Mask_logistics', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 96\n",
    "\n",
    "def get_accuracy(models_list, verbose=False, ret_acc=True):\n",
    "    ''' Calculates the accuracy for a given suite of models '''\n",
    "    if verbose:\n",
    "        print \"{:30} Accuracy\".format(\"Model\")\n",
    "    \n",
    "    acc_list = []\n",
    "    \n",
    "    for index,(feat,model) in enumerate(models_list):\n",
    "        predications = model.predict(train_PCA.tolist())\n",
    "        accuracy = np.mean(1 - abs(train_labels[:,index] - predications)/ IMAGE_SIZE)\n",
    "        acc_list.append(accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print \" - {f:<27} {a:.3%}\".format(f=FEATURES[index],a=accuracy)\n",
    "    \n",
    "    if ret_acc:\n",
    "        return acc_list\n",
    "    \n",
    "def compare_accuracies(iter_model_lists, model_labels):\n",
    "    ''' Compares the accuracy of different model suites '''\n",
    "    accuracies = []\n",
    "    \n",
    "    for mod in iter_model_lists:\n",
    "        accuracies.append( get_accuracy(mod, verbose=False) )\n",
    "    \n",
    "    # Print report\n",
    "    print \"   Feature     |   ACCURACIES:    \", '   '.join(model_labels)\n",
    "    \n",
    "    for f in xrange(len(accuracies[0])):  # Num of FEATURES\n",
    "        # format all the accuracies\n",
    "        _entry = \" - {:<27}   \".format(FEATURES[f])\n",
    "        for m in xrange(len(accuracies)):\n",
    "            _entry += \" {:.2%}  \".format(accuracies[m][f])\n",
    "        \n",
    "        print _entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                          Accuracy\n",
      " - left_eye_center_x           99.577%\n",
      " - left_eye_center_y           99.363%\n",
      " - right_eye_center_x          99.556%\n",
      " - right_eye_center_y          99.638%\n",
      " - left_eye_inner_corner_x     99.288%\n",
      " - left_eye_inner_corner_y     99.606%\n",
      " - left_eye_outer_corner_x     99.395%\n",
      " - left_eye_outer_corner_y     99.510%\n",
      " - right_eye_inner_corner_x    99.448%\n",
      " - right_eye_inner_corner_y    99.574%\n",
      " - right_eye_outer_corner_x    99.449%\n",
      " - right_eye_outer_corner_y    99.445%\n",
      " - left_eyebrow_inner_end_x    98.849%\n",
      " - left_eyebrow_inner_end_y    99.006%\n",
      " - left_eyebrow_outer_end_x    99.310%\n",
      " - left_eyebrow_outer_end_y    99.045%\n",
      " - right_eyebrow_inner_end_x   99.249%\n",
      " - right_eyebrow_inner_end_y   99.010%\n",
      " - right_eyebrow_outer_end_x   98.674%\n",
      " - right_eyebrow_outer_end_y   98.832%\n",
      " - nose_tip_x                  98.912%\n",
      " - nose_tip_y                  99.518%\n",
      " - mouth_left_corner_x         99.031%\n",
      " - mouth_left_corner_y         99.577%\n",
      " - mouth_right_corner_x        99.138%\n",
      " - mouth_right_corner_y        99.535%\n",
      " - mouth_center_top_lip_x      99.266%\n",
      " - mouth_center_top_lip_y      99.100%\n",
      " - mouth_center_bottom_lip_x   99.357%\n",
      " - mouth_center_bottom_lip_y   99.030%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.99577005451713385,\n",
       " 0.99362830996884721,\n",
       " 0.99555588006230533,\n",
       " 0.99638337227414342,\n",
       " 0.99288356697819324,\n",
       " 0.99606211059190042,\n",
       " 0.99394957165109021,\n",
       " 0.99510319314641749,\n",
       " 0.99447527258566959,\n",
       " 0.99573598130841123,\n",
       " 0.99448987538940792,\n",
       " 0.99445093457943923,\n",
       " 0.98848812305295952,\n",
       " 0.9900603582554518,\n",
       " 0.99309774143302176,\n",
       " 0.99044976635514015,\n",
       " 0.99248929127725838,\n",
       " 0.99010416666666679,\n",
       " 0.98674065420560753,\n",
       " 0.98832262461059184,\n",
       " 0.98912091121495327,\n",
       " 0.99517620716510913,\n",
       " 0.99031347352024934,\n",
       " 0.99577492211838015,\n",
       " 0.9913843457943925,\n",
       " 0.99535144080996873,\n",
       " 0.99265965732087247,\n",
       " 0.99100467289719629,\n",
       " 0.99357476635514019,\n",
       " 0.99030373831775698]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(PCA_logistics,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
