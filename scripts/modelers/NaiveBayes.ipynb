{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the path\n",
    "import sys, os\n",
    "\n",
    "pathArr = os.getcwd().split(\"/\")\n",
    "scriptPath = '/'.join(map(str, pathArr[:len(pathArr)-1]))\n",
    "sys.path.append(scriptPath)\n",
    "\n",
    "# import my tools\n",
    "from tools import save4later, submit, getdata\n",
    "\n",
    "# import the sklearn libraries and numpy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define accuracy calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 96\n",
    "\n",
    "def get_accuracy(models_list, verbose=False, ret_acc=True):\n",
    "    ''' Calculates the accuracy for a given suite of models '''\n",
    "    if verbose:\n",
    "        print \"{:30} Accuracy\".format(\"Model\")\n",
    "    \n",
    "    acc_list = []\n",
    "    \n",
    "    for index,(feat,model) in enumerate(models_list):\n",
    "        predications = model.predict(train_data.tolist())\n",
    "        accuracy = np.mean(1 - abs(train_labels[:,index] - predications)/ IMAGE_SIZE)\n",
    "        acc_list.append(accuracy)\n",
    "\n",
    "        if verbose:\n",
    "            print \" - {f:<27} {a:.3%}\".format(f=FEATURES[index],a=accuracy)\n",
    "    \n",
    "    if ret_acc:\n",
    "        return acc_list\n",
    "    \n",
    "def compare_accuracies(iter_model_lists, model_labels):\n",
    "    ''' Compares the accuracy of different model suites '''\n",
    "    accuracies = []\n",
    "    \n",
    "    for mod in iter_model_lists:\n",
    "        accuracies.append( get_accuracy(mod, verbose=False) )\n",
    "    \n",
    "    # Print report\n",
    "    print \"   Feature     |   ACCURACIES:    \", '   '.join(model_labels)\n",
    "    \n",
    "    for f in xrange(len(accuracies[0])):  # Num of FEATURES\n",
    "        # format all the accuracies\n",
    "        _entry = \" - {:<27}   \".format(FEATURES[f])\n",
    "        for m in xrange(len(accuracies)):\n",
    "            _entry += \" {:.2%}  \".format(accuracies[m][f])\n",
    "        \n",
    "        print _entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 30\n",
      "Training dataset size:  (2140,)\n",
      "Test dataset size:  (1783,)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "_loaded = getdata.load_data(0, test=True, nonas=True)\n",
    "\n",
    "FEATURES = _loaded['features']\n",
    "print 'Number of features:', len(FEATURES)\n",
    "\n",
    "train_data = _loaded['training']['data']\n",
    "train_labels = _loaded['training']['labels']\n",
    "print 'Training dataset size: ', train_data.shape\n",
    "\n",
    "test_data = _loaded['test']['data']\n",
    "print 'Test dataset size: ', test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Naive Bayes models for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an array to store the multinomial naive bayes models\n",
    "multinomials = []\n",
    "\n",
    "# initalize a set of reasonable alphas that we would like to search for the optimal alpha\n",
    "MNparameters = {'alpha':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# loop through all the facial features\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "    \n",
    "    # initalize the multinomail naive bayes model\n",
    "    Multinomial = MultinomialNB()\n",
    "\n",
    "    # set the alpha search with the given alpha options and the Multinomial model\n",
    "    alpha_search = GridSearchCV(Multinomial,MNparameters)\n",
    "\n",
    "    # fit the Gridsearch model on the training data\n",
    "    alpha_search.fit(train_data.tolist(),train_labels[:,index])\n",
    "\n",
    "    # find the best parameter\n",
    "    best_alpha = alpha_search.best_params_\n",
    "\n",
    "    # fit a model with the best alpha\n",
    "    Multinomial_optimal = MultinomialNB(alpha = best_alpha['alpha'])\n",
    "    Multinomial_optimal.fit(train_data.tolist(),train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the model and its associated facial feature\n",
    "    appending = facial_feature, Multinomial_optimal\n",
    "    \n",
    "    # append the model and its name to our list\n",
    "    multinomials.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(multinomials, 'MultinomialNB', \n",
    "                      'Multinomial naive bayes with non-preprocessed data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "multinomials = save4later.load_model(\"MultinomialNB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the models on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (0.2s)\n",
      "Predicting \"left_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"nose_tip_x\"... done! (0.1s)\n",
      "Predicting \"nose_tip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (0.2s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (0.2s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (0.2s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (0.1s)\n",
      "\n",
      "... Created the csv file: ../../data/submissions/multinomials_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, multinomials, 'multinomials', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit naive bayes models on 'masked' preprocessed data\n",
    "We use face detect to remove the background before putting the data through our naive bayes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "# load the masked training data\n",
    "train_masked = save4later.load_preprod(\"masked_nonas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an array to store the multinomial naive bayes models\n",
    "Mask_multinomials = []\n",
    "\n",
    "# initalize a set of reasonable alphas that we would like to search for the optimal alpha\n",
    "MNparameters = {'alpha':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# loop through all the facial features\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "    \n",
    "    # initalize the multinomail naive bayes model\n",
    "    Multinomial = MultinomialNB()\n",
    "\n",
    "    # set the alpha search with the given alpha options and the Multinomial model\n",
    "    alpha_search = GridSearchCV(Multinomial,MNparameters)\n",
    "\n",
    "    # fit the Gridsearch model on the training data\n",
    "    alpha_search.fit(train_masked,train_labels[:,index])\n",
    "\n",
    "    # find the best parameter\n",
    "    best_alpha = alpha_search.best_params_\n",
    "\n",
    "    # fit a model with the best alpha\n",
    "    Multinomial_optimal = MultinomialNB(alpha = best_alpha['alpha'])\n",
    "    Multinomial_optimal.fit(train_masked,train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the model and its associated facial feature\n",
    "    appending = facial_feature, Multinomial_optimal\n",
    "    \n",
    "    # append the model and its name to our list\n",
    "    Mask_multinomials.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(Mask_multinomials, 'MultinomialNB_Mask', \n",
    "                      'Multinomial naive bayes with masked data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (0.2s)\n",
      "Predicting \"left_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (0.2s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"nose_tip_x\"... done! (0.1s)\n",
      "Predicting \"nose_tip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (0.1s)\n",
      "\n",
      "... Created the csv file: ../../data/submissions/Mask_multinomials_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, Mask_multinomials, 'Mask_multinomials', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Naive Bayes on 'sobel' training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "# load the sobel training data\n",
    "train_sobel = save4later.load_preprod(\"sobel_nonas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an array to store the multinomial naive bayes models\n",
    "sobel_multinomials = []\n",
    "\n",
    "# initalize a set of reasonable alphas that we would like to search for the optimal alpha\n",
    "MNparameters = {'alpha':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# loop through all the facial features\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "    \n",
    "    # initalize the multinomail naive bayes model\n",
    "    Multinomial = MultinomialNB()\n",
    "\n",
    "    # set the alpha search with the given alpha options and the Multinomial model\n",
    "    alpha_search = GridSearchCV(Multinomial,MNparameters)\n",
    "\n",
    "    # fit the Gridsearch model on the training data\n",
    "    alpha_search.fit(train_sobel,train_labels[:,index])\n",
    "\n",
    "    # find the best parameter\n",
    "    best_alpha = alpha_search.best_params_\n",
    "\n",
    "    # fit a model with the best alpha\n",
    "    Multinomial_optimal = MultinomialNB(alpha = best_alpha['alpha'])\n",
    "    Multinomial_optimal.fit(train_sobel,train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the model and its associated facial feature\n",
    "    appending = facial_feature, Multinomial_optimal\n",
    "    \n",
    "    # append the model and its name to our list\n",
    "    sobel_multinomials.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(sobel_multinomials, 'MultinomialNB_sobel', \n",
    "                      'Multinomial naive bayes with masked data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "sobel_multinomials = save4later.load_model(\"MultinomialNB_sobel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test data using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"nose_tip_x\"... done! (0.1s)\n",
      "Predicting \"nose_tip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (0.1s)\n",
      "\n",
      "... Created the csv file: ../../data/submissions/multinomials_sobel_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, sobel_multinomials, 'multinomials_sobel', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the naive bayes model on blurred HOG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "# load the blurred HOG training data\n",
    "train_HOG = save4later.load_preprod(\"bhog_nonas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an array to store the multinomial naive bayes models\n",
    "HOG_multinomials = []\n",
    "\n",
    "# initalize a set of reasonable alphas that we would like to search for the optimal alpha\n",
    "MNparameters = {'alpha':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# loop through all the facial features\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "    \n",
    "    # initalize the multinomail naive bayes model\n",
    "    Multinomial = MultinomialNB()\n",
    "\n",
    "    # set the alpha search with the given alpha options and the Multinomial model\n",
    "    alpha_search = GridSearchCV(Multinomial,MNparameters)\n",
    "\n",
    "    # fit the Gridsearch model on the training data\n",
    "    alpha_search.fit(train_HOG,train_labels[:,index])\n",
    "\n",
    "    # find the best parameter\n",
    "    best_alpha = alpha_search.best_params_\n",
    "\n",
    "    # fit a model with the best alpha\n",
    "    Multinomial_optimal = MultinomialNB(alpha = best_alpha['alpha'])\n",
    "    Multinomial_optimal.fit(train_HOG,train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the model and its associated facial feature\n",
    "    appending = facial_feature, Multinomial_optimal\n",
    "    \n",
    "    # append the model and its name to our list\n",
    "    HOG_multinomials.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(HOG_multinomials, 'MultinomialNB_HOG', \n",
    "                      'Multinomial naive bayes with blurred HOG data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "HOG_multinomials = save4later.load_model(\"MultinomialNB_HOG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (0.2s)\n",
      "Predicting \"left_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"nose_tip_x\"... done! (0.1s)\n",
      "Predicting \"nose_tip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (0.1s)\n",
      "\n",
      "... Created the csv file: ../../data/submissions/multinomials_HOG_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, HOG_multinomials, 'multinomials_HOG', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a naive bayes model on data with a Laplace & Gaussian transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "# load the laplace & gaussian training data\n",
    "train_LapG = save4later.load_preprod(\"lapgauss_nonas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an array to store the multinomial naive bayes models\n",
    "LapG_multinomials = []\n",
    "\n",
    "# initalize a set of reasonable alphas that we would like to search for the optimal alpha\n",
    "MNparameters = {'alpha':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# loop through all the facial features\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "    \n",
    "    # initalize the multinomail naive bayes model\n",
    "    Multinomial = MultinomialNB()\n",
    "\n",
    "    # set the alpha search with the given alpha options and the Multinomial model\n",
    "    alpha_search = GridSearchCV(Multinomial,MNparameters)\n",
    "\n",
    "    # fit the Gridsearch model on the training data\n",
    "    alpha_search.fit(train_LapG,train_labels[:,index])\n",
    "\n",
    "    # find the best parameter\n",
    "    best_alpha = alpha_search.best_params_\n",
    "\n",
    "    # fit a model with the best alpha\n",
    "    Multinomial_optimal = MultinomialNB(alpha = best_alpha['alpha'])\n",
    "    Multinomial_optimal.fit(train_LapG,train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the model and its associated facial feature\n",
    "    appending = facial_feature, Multinomial_optimal\n",
    "    \n",
    "    # append the model and its name to our list\n",
    "    LapG_multinomials.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(LapG_multinomials, 'MultinomialNB_LapG', \n",
    "                      'Multinomial naive bayes with Laplace and Gaussian transformed data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "LapG_multinomials = save4later.load_model(\"MultinomialNB_LapG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"... done! (0.2s)\n",
      "Predicting \"left_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_center_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"left_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_inner_corner_y\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_x\"... done! (0.1s)\n",
      "Predicting \"right_eye_outer_corner_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"left_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_inner_end_y\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_x\"... done! (0.1s)\n",
      "Predicting \"right_eyebrow_outer_end_y\"... done! (0.1s)\n",
      "Predicting \"nose_tip_x\"... done! (0.1s)\n",
      "Predicting \"nose_tip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_left_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_x\"... done! (0.1s)\n",
      "Predicting \"mouth_right_corner_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_top_lip_y\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_x\"... done! (0.1s)\n",
      "Predicting \"mouth_center_bottom_lip_y\"... done! (0.1s)\n",
      "\n",
      "... Created the csv file: ../../data/submissions/multinomials_LapG_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, LapG_multinomials, 'multinomials_LapG', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a naive bayes model on Gaussian blurred data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "# load the gaussian blurred training data\n",
    "train_gauss = save4later.load_preprod(\"gauss_nonas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an array to store the multinomial naive bayes models\n",
    "gauss_multinomials = []\n",
    "\n",
    "# initalize a set of reasonable alphas that we would like to search for the optimal alpha\n",
    "MNparameters = {'alpha':[0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# loop through all the facial features\n",
    "for index,facial_feature in enumerate(FEATURES):\n",
    "    \n",
    "    # initalize the multinomail naive bayes model\n",
    "    Multinomial = MultinomialNB()\n",
    "\n",
    "    # set the alpha search with the given alpha options and the Multinomial model\n",
    "    alpha_search = GridSearchCV(Multinomial,MNparameters)\n",
    "\n",
    "    # fit the Gridsearch model on the training data\n",
    "    alpha_search.fit(train_gauss,train_labels[:,index])\n",
    "\n",
    "    # find the best parameter\n",
    "    best_alpha = alpha_search.best_params_\n",
    "\n",
    "    # fit a model with the best alpha\n",
    "    Multinomial_optimal = MultinomialNB(alpha = best_alpha['alpha'])\n",
    "    Multinomial_optimal.fit(train_gauss,train_labels[:,index])\n",
    "    \n",
    "    # create a tuple with the model and its associated facial feature\n",
    "    appending = facial_feature, Multinomial_optimal\n",
    "    \n",
    "    # append the model and its name to our list\n",
    "    gauss_multinomials.append(appending)\n",
    "\n",
    "# save the models for later\n",
    "save4later.save_model(gauss_multinomials, 'MultinomialNB_gauss', \n",
    "                      'Multinomial naive bayes with Gaussian blurred data with no NAs',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pk\n"
     ]
    }
   ],
   "source": [
    "gauss_multinomials = save4later.load_model(\"MultinomialNB_gauss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting \"left_eye_center_x\"..."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1783,9216) and (18432,22) not aligned: 9216 (dim 1) != 18432 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-ffc041344d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauss_multinomials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multinomials_gauss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Alex/Documents/Berkeley/1601Spring/W207/PS4/facial-keypoint-detection/scripts/tools/submit.pyc\u001b[0m in \u001b[0;36mcreate_generate\u001b[0;34m(test, models, label, verbose)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mpredicted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# create the csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alex/Documents/Berkeley/1601Spring/W207/PS4/facial-keypoint-detection/scripts/tools/submit.pyc\u001b[0m in \u001b[0;36mcreate_submission\u001b[0;34m(test, models, label, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0m_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# start timer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mpredicted_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0m_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alex/miniconda2/envs/fkd/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alex/miniconda2/envs/fkd/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         return (safe_sparse_dot(X, self.feature_log_prob_.T)\n\u001b[0m\u001b[1;32m    673\u001b[0m                 + self.class_log_prior_)\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alex/miniconda2/envs/fkd/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1783,9216) and (18432,22) not aligned: 9216 (dim 1) != 18432 (dim 0)"
     ]
    }
   ],
   "source": [
    "submit.create_generate(test_data, gauss_multinomials, 'multinomials_gauss', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the accuracies of the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2140,9216) and (18432,22) not aligned: 9216 (dim 1) != 18432 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d9ceecd778b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmultinomials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMask_multinomials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msobel_multinomials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHOG_multinomials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLapG_multinomials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgauss_multinomials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_model_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Regular NB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NB with masking\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NB with sobel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NB with HOG\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NB with Laplace & Gaussian\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NB with Gaussian\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcompare_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_model_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-ceb2d9e577b1>\u001b[0m in \u001b[0;36mcompare_accuracies\u001b[0;34m(iter_model_lists, model_labels)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_model_lists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Print report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-ceb2d9e577b1>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(models_list, verbose, ret_acc)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredications\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredications\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0macc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alex/miniconda2/envs/fkd/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alex/miniconda2/envs/fkd/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         return (safe_sparse_dot(X, self.feature_log_prob_.T)\n\u001b[0m\u001b[1;32m    673\u001b[0m                 + self.class_log_prior_)\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alex/miniconda2/envs/fkd/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2140,9216) and (18432,22) not aligned: 9216 (dim 1) != 18432 (dim 0)"
     ]
    }
   ],
   "source": [
    "all_models = [multinomials,Mask_multinomials,sobel_multinomials,HOG_multinomials,LapG_multinomials,gauss_multinomials]\n",
    "all_model_names = [\"Regular NB\", \"NB with masking\", \"NB with sobel\", \"NB with HOG\", \"NB with Laplace & Gaussian\", \"NB with Gaussian\"]\n",
    "compare_accuracies(all_models,all_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
