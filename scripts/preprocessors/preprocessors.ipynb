{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessors  \n",
    "This notebook makes use of the findings of the explorations notebooks, and using the `tools/save4later.py` module, creates and stores the preprod's appropriately for the models to load seamlessly.  \n",
    "\n",
    "First, let's import the `tools/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import our tools\n",
    "import sys\n",
    "sys.path.append('/Users/will/Github/facial-keypoint-detection/scripts')\n",
    "\n",
    "# Import submit module from our tools subfolder\n",
    "from tools import getdata, save4later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's import all our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 30\n",
      "Training dataset size:  (7049,)\n"
     ]
    }
   ],
   "source": [
    "# Load data (no dev)\n",
    "_loaded = getdata.load_data(0, test=False, nonas=False)\n",
    "\n",
    "FEATURES = _loaded['features']\n",
    "print 'Number of features:', len(FEATURES)\n",
    "\n",
    "train_data = _loaded['training']['data']\n",
    "train_labels = _loaded['training']['labels']\n",
    "print 'Training dataset size: ', train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents  \n",
    "\n",
    "* **Noise Cancelling**:\n",
    "   * Mask Faces  \n",
    "\n",
    "\n",
    "* **Edge Detection**:\n",
    "   * Sobel filter  \n",
    "   * Laplace transform  \n",
    "\n",
    "\n",
    "* **Noise Reduction**:\n",
    "   * Gaussian blur  \n",
    "   * Mean-shift  \n",
    " \n",
    "\n",
    "* **Finding Contours**:  \n",
    "   * Histogram of Oriented Gradients  \n",
    "   * Watershed algorithm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mask Faces\n",
    "Using `explorations/face-detection.ipynb` creates the masked-face preprod.  \n",
    "\n",
    "Process:  \n",
    "* All the images are run through OpenCV's face-detector (*see the exploration notebook for more detail and references on this algorithm*)  \n",
    "* Images for which just one face is detected are masked (set all pixels outside the detected face to 0)  \n",
    "\n",
    "*IMPORTANT NOTE* - the base `environment.yml` does not include installation of OpenCV2, since it is an optional branch in this project. In order to get the build including OpenCV refer to with `/adv-envs/environment-ocv.yml`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CASC_PATH = '../haarcascade_frontalface_default.xml'\n",
    "\n",
    "# Create the haar cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(CASC_PATH)\n",
    "\n",
    "def detect_face(img, min_face_size):\n",
    "    ''' Detect faces in the image'''\n",
    "    face = faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(min_face_size, min_face_size),\n",
    "        flags = cv2.cv.CV_HAAR_SCALE_IMAGE)\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_faces(faces):\n",
    "    ''' Masked faces detected '''\n",
    "    masked = []\n",
    "    \n",
    "    for i,_face in enumerate(faces):\n",
    "        old_img = train_data[_face].reshape(96,96)\n",
    "\n",
    "        # detect face\n",
    "        _face = detect_face(old_img, min_face_size=10)\n",
    "                        \n",
    "        # only crop if we detect one face\n",
    "        if len(_face) == 1:\n",
    "            x, y, w, h = _face[0]\n",
    "            new_img = np.zeros_like(old_img)\n",
    "            new_img[y:y+h, x:x+w] = old_img[y:y+h, x:x+w]\n",
    "            \n",
    "            masked.append(new_img.flatten())\n",
    "            \n",
    "        else:\n",
    "            masked.append(old_img.flatten())\n",
    "        \n",
    "    return masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's **mask** all the images now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_train_data = mask_faces( range(len(train_data)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now save using the `save4later` tool ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save4later.save_preprod(masked_train_data, 'masked',\n",
    "                        description='Masked data (removed background of all faces)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    PREPROC'D DATASETS\n",
      "    ===================\n",
      " Total: 2\n",
      "\n",
      "  + masked.pk : Masked data (removed background of all faces)\n",
      "  + test.pk : This is a test\n"
     ]
    }
   ],
   "source": [
    "save4later.list_preprods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, there it is! On to the next one then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
