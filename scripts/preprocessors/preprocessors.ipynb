{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessors  \n",
    "This notebook makes use of the findings of the explorations notebooks, and using the `tools/save4later.py` module, creates and stores the preprod's appropriately for the models to load seamlessly.  \n",
    "\n",
    "First, let's import the `tools/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import our tools\n",
    "import sys\n",
    "sys.path.append('/Users/will/Github/facial-keypoint-detection/scripts')\n",
    "\n",
    "# Import submit module from our tools subfolder\n",
    "from tools import getdata, save4later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's import all our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 30\n",
      "Training dataset size:  (7049,)\n"
     ]
    }
   ],
   "source": [
    "# Load data (no dev) WITH NONAs set to False --> ~7k\n",
    "_loaded = getdata.load_data(0, test=False, nonas=False)\n",
    "\n",
    "FEATURES = _loaded['features']\n",
    "print 'Number of features:', len(FEATURES)\n",
    "\n",
    "train_data = _loaded['training']['data']\n",
    "train_labels = _loaded['training']['labels']\n",
    "print 'Training dataset size: ', train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size:  (2140,)\n"
     ]
    }
   ],
   "source": [
    "# Load data WITH NONAs set to True --> ~2k\n",
    "_loaded_nonas = getdata.load_data(0, test=False, nonas=True)\n",
    "\n",
    "train_nonas_data = _loaded_nonas['training']['data']\n",
    "train_nonas_labels = _loaded_nonas['training']['labels']\n",
    "print 'Training dataset size: ', train_nonas_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents  \n",
    "\n",
    "* **Noise Cancelling**:\n",
    "   * Mask Faces  \n",
    "\n",
    "\n",
    "* **Edge Detection**:\n",
    "   * Sobel filter  \n",
    "   * Laplace transform  \n",
    "\n",
    "\n",
    "* **Noise Reduction**:\n",
    "   * Gaussian blur  \n",
    "   * Region Adjacency Graph (RAG)  \n",
    " \n",
    "\n",
    "* **Finding Contours**:  \n",
    "   * Histogram of Oriented Gradients (HOG)  \n",
    "   * Watershed algorithm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Noise Cancelling: Mask Faces\n",
    "Using `explorations/face-detection.ipynb` creates the masked-face preprod.  \n",
    "\n",
    "Process:  \n",
    "* All the images are run through OpenCV's face-detector (*see the exploration notebook for more detail and references on this algorithm*)  \n",
    "* Images for which just one face is detected are masked (set all pixels outside the detected face to 0)  \n",
    "\n",
    "*IMPORTANT NOTE* - the base `environment.yml` does not include installation of OpenCV2, since it is an optional branch in this project. In order to get the build including OpenCV refer to with `/adv-envs/environment-ocv.yml`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CASC_PATH = '../haarcascade_frontalface_default.xml'\n",
    "\n",
    "# Create the haar cascade classifier\n",
    "faceCascade = cv2.CascadeClassifier(CASC_PATH)\n",
    "\n",
    "def detect_face(img, min_face_size):\n",
    "    ''' Detect faces in the image'''\n",
    "    face = faceCascade.detectMultiScale(\n",
    "        img,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(min_face_size, min_face_size),\n",
    "        flags = cv2.cv.CV_HAAR_SCALE_IMAGE)\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_faces(dataset):\n",
    "    ''' Masked faces detected '''\n",
    "    masked = []\n",
    "    \n",
    "    for i in xrange(len(dataset)):\n",
    "        old_img = dataset[i].reshape(96,96)\n",
    "\n",
    "        # detect face\n",
    "        _face = detect_face(old_img, min_face_size=10)\n",
    "                        \n",
    "        # only crop if we detect one face\n",
    "        if len(_face) == 1:\n",
    "            x, y, w, h = _face[0]\n",
    "            new_img = np.zeros_like(old_img)\n",
    "            new_img[y:y+h, x:x+w] = old_img[y:y+h, x:x+w]\n",
    "            \n",
    "            masked.append(new_img.flatten())\n",
    "            \n",
    "        else:\n",
    "            masked.append(old_img.flatten())\n",
    "        \n",
    "    return masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's **mask** all the images now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_train_data = mask_faces( train_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now save using the `save4later` tool ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save4later.save_preprod(masked_train_data, 'masked',\n",
    "                        description='Masked data (removed background of all faces)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    PREPROC'D DATASETS\n",
      "    ===================\n",
      " Total: 2\n",
      "\n",
      "  + masked.pk : Masked data (removed background of all faces)\n",
      "  + test.pk : This is a test\n"
     ]
    }
   ],
   "source": [
    "save4later.list_preprods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, there it is! Now let's do the same for the NoNAs dataset as well (only ~2k faces) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masked_train_nonas_data = mask_faces(train_nonas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save4later.save_preprod(masked_train_nonas_data, 'masked_nonas',\n",
    "                        description='Masked data (only faces with no NA features)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    PREPROC'D DATASETS\n",
      "    ===================\n",
      " Total: 3\n",
      "\n",
      "  + masked.pk : Masked data (removed background of all faces)\n",
      "  + test.pk : This is a test\n",
      "  + masked_nonas.pk : Masked data (only faces with no NA features)\n"
     ]
    }
   ],
   "source": [
    "save4later.list_preprods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Edge detection\n",
    "\n",
    "For more detail refer to `explorations/image-processing.ipynb` notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_set(transform, dataset, keep_orig=False):\n",
    "    ''' Applies preprocessor, and appends result to the original image '''\n",
    "    transformed = []\n",
    "    \n",
    "    for i in xrange(len(dataset)):\n",
    "        old_img = dataset[i].reshape(96,96)\n",
    "        new_img = transform(old_img)\n",
    "        \n",
    "        if keep_orig:\n",
    "            new_entry = np.hstack( (old_img.flatten(),new_img.flatten()) )\n",
    "        else:\n",
    "            new_entry = new_img.flatten()\n",
    "        \n",
    "        transformed.append(new_entry)\n",
    "\n",
    "    return transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel Filter  \n",
    "\n",
    "We are going to add the sobel filtered image to the image (not replace the original), so we will now have $96*96*2$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.filters import sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sobel_train_nonas_data = preprocess_set(sobel, train_nonas_data, keep_orig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save4later.save_preprod(sobel_train_nonas_data, 'orig_sobel_nonas',\n",
    "                        description='Original + Sobel filter (only faces with no NA features)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sobel_noorig_train_data = preprocess_set(sobel, train_nonas_data)\n",
    "save4later.save_preprod(sobel_noorig_train_data, 'sobel_nonas',\n",
    "                        description='Sobel filter (only faces with no NA features)',\n",
    "                        overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    PREPROC'D DATASETS\n",
      "    ===================\n",
      " Total: 5\n",
      "\n",
      "  + test.pk : This is a test\n",
      "  + masked.pk : Masked data (removed background of all faces)\n",
      "  + orig_sobel_nonas.pk : Original + Sobel filter (only faces with no NA features)\n",
      "  + sobel_nonas.pk : Sobel filter (only faces with no NA features)\n",
      "  + masked_nonas.pk : Masked data (only faces with no NA features)\n"
     ]
    }
   ],
   "source": [
    "save4later.list_preprods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Laplace Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Reduction  \n",
    "\n",
    "### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region Adjacency Graph (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Contours\n",
    "\n",
    "### Histogram of Oriented Gradients (HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
